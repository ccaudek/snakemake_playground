Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
all                1              1              1
make_report        1              1              1
total              2              1              1

Select jobs to execute...

[Fri Jan  7 13:17:03 2022]
rule make_report:
    input: scripts/data/penguins.csv, ../results/data/processed/penguin_subset.rds, ../results/tables/tab_1.txt, ../results/plots/figure_2.pdf
    output: ../results/reports/report.html
    log: ../results/logs/make_report.log
    jobid: 4
    resources: tmpdir=/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T

[Fri Jan  7 13:17:07 2022]
Finished job 4.
1 of 2 steps (50%) done
Select jobs to execute...

[Fri Jan  7 13:17:07 2022]
localrule all:
    input: ../results/plots/figure_1.pdf, ../results/plots/figure_2.pdf, ../results/data/processed/penguin_subset.rds, ../results/tables/tab_1.txt, ../results/plots/hist_1.pdf, ../results/reports/report.html
    jobid: 0
    resources: tmpdir=/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T

[Fri Jan  7 13:17:07 2022]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /Users/corrado/Documents/snakemake_workflows/snakemake_playground/playground/workflow/.snakemake/log/2022-01-07T131703.431909.snakemake.log
